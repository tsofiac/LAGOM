epoch	training_loss	validation_loss	validation_token_accuracy	fraction_invalid	accuracy_top_1	lr-Adam
0	1.1725035					
1	0.9585044	0.80133444	0.77089965	0.25868055	0.00853588	
2	0.6744467	0.78325856	0.7666635	0.38556135	0.00390625	
3	0.57917386	0.7603455	0.78127426	0.3382523	0.01707176	
4	0.5468276	0.7493942	0.78695756	0.3521412	0.02097801	
5	0.65037036	0.72725505	0.7904714	0.41608796	0.01171875	
6	0.32906976	0.7277734	0.7957361	0.3592303	0.015625	
7	0.3724818	0.71489984	0.79903185	0.39438656	0.015625	
8	0.3673913	0.71232903	0.80126697	0.3670428	0.01171875	
9	0.26579574	0.6869821	0.8056637	0.45167825	0.015625	0.0007505656
10	0.22352181	0.6845251	0.8141937	0.40046296	0.015625	0.0007505656
11	0.17207064	0.695358	0.81288296	0.4573206	0.020254629	0.0007505656
12	0.34428576	0.6815789	0.82082605	0.38483796	0.02734375	0.0007505656
13	0.17357735	0.7408048	0.8202348	0.47757524	0.0234375	0.0007505656
14	0.10570118	0.7140514	0.8219608	0.3965567	0.0390625	0.0007505656
15	0.22926451	0.7260581	0.8282207	0.36385995	0.03515625	0.0007505656
16	0.12552066	0.78630674	0.81861365	0.4309896	0.02734375	0.0007505656
17	0.15341851	0.8209019	0.8196224	0.40118635	0.03197338	0.0007505656
18	0.20501462	0.81668174	0.8270973	0.4651331	0.0234375	0.0007505656
19	0.053702135	0.88227135	0.8223703	0.51490164	0.02734375	0.0009520247
20	0.04641161	0.8724214	0.8276603	0.46903935	0.028067129	0.0009520247
21	0.03398525	0.9589214	0.82621574	0.43706596	0.03978588	0.0009520247
22	0.0412018	0.9393184	0.82969713	0.4626736	0.02734375	0.0009520247
23	0.040565953	1.0368814	0.8230372	0.47439235	0.0234375	0.0009520247
24	0.05662084	0.99123275	0.8284976	0.41681135	0.020254629	0.0009520247
25	0.10361168	1.0048817	0.82836896	0.43070024	0.03587963	0.0009520247
26	0.028344385	1.0207132	0.8304864	0.42042825	0.03197338	0.0009520247
27	0.08451877	1.0394214	0.82967687	0.44632524	0.03587963	0.0009520247
28	0.031586573	1.069451	0.8307049	0.42216435	0.03197338	0.0009520247
29	0.058116037	1.1102049	0.82919973	0.45630786	0.041232638	0.00061648514
30	0.019923009	1.1128553	0.82975245	0.4758391	0.03197338	0.00061648514
31	0.017634165	1.1201937	0.8287304	0.4548611	0.041232638	0.00061648514
32	0.036879804	1.1288517	0.8302131	0.45167825	0.037326388	0.00061648514
33	0.012840966	1.1511245	0.83042693	0.45949075	0.037326388	0.00061648514
34	0.025759619	1.1930879	0.8287462	0.4548611	0.041232638	0.00061648514
35	0.0054213074	1.1927637	0.8296343	0.44560185	0.02488426	0.00061648514
36	0.0116554005	1.203239	0.8315917	0.43778935	0.02879051	0.00061648514
37	0.034020144	1.2009736	0.83231074	0.463397	0.02879051	0.00061648514
38	0.0361098	1.2167091	0.83049476	0.4680266	0.03125	0.00061648514
39	0.017032789	1.220819	0.8307879	0.46730325	0.040509257	0.00019388182
40	0.022231184	1.2255521	0.83040214	0.46195024	0.032696757	0.00019388182
41	0.012107396	1.2275684	0.83097726	0.4470486	0.032696757	0.00019388182
42	0.037261583	1.227303	0.8318095	0.4346065	0.036603007	0.00019388182
43	0.04560704	1.2239591	0.83189833	0.42288774	0.036603007	0.00019388182
44	0.022528766	1.220759	0.8326975	0.42751735	0.036603007	0.00019388182
45	0.019169427	1.2215289	0.8334214	0.42751735	0.036603007	0.00019388182
46	0.0107453475	1.2228802	0.8333349	0.43532985	0.036603007	0.00019388182
47	0.011114315	1.2245625	0.83286536	0.44314235	0.036603007	0.00019388182
48	0.030174224	1.2255679	0.8326974	0.44314235	0.036603007	0.00019388182
49	0.021445455	1.2260334	0.83236766	0.4470486	0.036603007	8.392505e-08
