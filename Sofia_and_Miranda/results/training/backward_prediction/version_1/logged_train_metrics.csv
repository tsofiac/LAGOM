epoch	training_loss	validation_loss	validation_token_accuracy	fraction_invalid	accuracy_top_1	lr-Adam
0	1.3705463					
1	1.0591354	1.2267915	0.71696025	0.22078125	0.00546875	
2	0.80884403	0.9427725	0.7419433	0.34546876	0.00703125	
3	0.6502453	0.7728132	0.7684469	0.44109374	0.01015625	
4	0.59213984	0.6236908	0.8047882	0.34375	0.01796875	
5	0.75504434	0.52376884	0.8423507	0.3284375	0.03203125	
6	0.34408817	0.44314584	0.86404353	0.37375	0.07421875	
7	0.4062386	0.37169224	0.8813321	0.37375	0.090625	
8	0.24291115	0.32196015	0.89720607	0.325	0.151875	
9	0.2605733	0.27764967	0.9067868	0.37796876	0.1878125	
10	0.17021249	0.24452771	0.918733	0.38140625	0.22015625	
11	0.23998983	0.206693	0.9288238	0.3696875	0.25296876	
12	0.11012308	0.17869294	0.9378882	0.389375	0.2725	
13	0.078130685	0.15058737	0.9460918	0.3796875	0.32484376	
14	0.27540368	0.13405176	0.95129484	0.395625	0.3509375	
15	0.08946966	0.11626185	0.95778954	0.38203126	0.3853125	
16	0.08799548	0.10174173	0.9619812	0.3703125	0.4178125	0.0009951295
17	0.05862048	0.09295249	0.9654716	0.36640626	0.44390625	0.0009951295
18	0.041581426	0.09142006	0.96500635	0.3765625	0.46578124	0.0009951295
19	0.039652497	0.081278145	0.9700982	0.3671875	0.4859375	0.0009951295
20	0.026951741	0.0700193	0.97402376	0.37421876	0.51171875	0.0009951295
21	0.056149933	0.07146246	0.972086	0.36875	0.51453125	0.0009951295
22	0.040046792	0.06612525	0.9746809	0.39765626	0.5054687	0.0009951295
23	0.08804252	0.071475744	0.9746047	0.4534375	0.4575	0.0009951295
24	0.22121502	0.0598657	0.9779985	0.38046876	0.528125	0.0009951295
25	0.036398802	0.049358707	0.98151183	0.3796875	0.55078125	0.0009951295
26	0.045387074	0.047047887	0.98279643	0.3828125	0.5515625	0.0009951295
27	0.16351204	0.044620056	0.98303163	0.3984375	0.5453125	0.0009951295
28	0.014885194	0.04317871	0.98272866	0.375	0.5679687	0.0009951295
29	0.017992461	0.040606316	0.98518974	0.37578124	0.58203125	0.0009951295
30	0.0313626	0.032323875	0.98727506	0.37578124	0.590625	0.0009951295
31	0.016812189	0.033957172	0.9860053	0.375	0.5859375	0.0009951295
32	0.018292215	0.029810298	0.9890285	0.371875	0.5960938	0.0009951295
33	0.085675485	0.026463097	0.9897366	0.371875	0.5960938	0.0004725233
34	0.010334217	0.023556037	0.99136436	0.371875	0.6015625	0.0004725233
35	0.12672125	0.023098256	0.99144727	0.37421876	0.6039063	0.0004725233
36	0.051427625	0.020519756	0.99277776	0.375	0.6046875	0.0004725233
37	0.030021835	0.019129302	0.9932908	0.371875	0.6046875	0.0004725233
38	0.040474664	0.018072858	0.99387586	0.37265626	0.60546875	0.0004725233
39	0.006143731	0.016468719	0.99438804	0.37265626	0.6078125	0.0004725233
40	0.014702586	0.01664293	0.9943631	0.37265626	0.60859376	0.0004725233
41	0.005294966	0.015426003	0.99486756	0.37265626	0.6078125	0.0004725233
42	0.014114296	0.014516153	0.99504244	0.371875	0.60859376	0.0004725233
43	0.004880214	0.014177656	0.9950241	0.371875	0.60859376	0.0004725233
44	0.0036998084	0.013620135	0.99536484	0.371875	0.609375	0.0004725233
45	0.007837601	0.0133619085	0.9955104	0.371875	0.609375	0.0004725233
46	0.07212271	0.013279945	0.9956099	0.371875	0.609375	0.0004725233
47	0.023876404	0.013250092	0.9955538	0.371875	0.609375	0.0004725233
48	0.016091958	0.013215236	0.9955951	0.371875	0.609375	0.0004725233
49	0.012793743	0.013189609	0.99561805	0.371875	0.609375	2.2482898e-07
